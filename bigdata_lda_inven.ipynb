{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d1ce6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>GameName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>정성추 나름 체계적으로 게임이 진행되고있었네요  이런 스토리가</td>\n",
       "      <td>APEX LEGENDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-17</td>\n",
       "      <td>레이스 본명인  는 르네 일거에요두번 째  위에 점 빠진듯</td>\n",
       "      <td>APEX LEGENDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>스토리 보는거 정말 좋아하는 이런 정성 넘치는 정리 너무 감사합니다</td>\n",
       "      <td>APEX LEGENDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>와 시즌7까지는 어디서 볼 수 있을까요</td>\n",
       "      <td>APEX LEGENDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>업뎃내용갱신</td>\n",
       "      <td>APEX LEGENDS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                   text      GameName\n",
       "0  2020-11-12     정성추 나름 체계적으로 게임이 진행되고있었네요  이런 스토리가  APEX LEGENDS\n",
       "1  2020-11-17       레이스 본명인  는 르네 일거에요두번 째  위에 점 빠진듯  APEX LEGENDS\n",
       "2  2020-11-19  스토리 보는거 정말 좋아하는 이런 정성 넘치는 정리 너무 감사합니다  APEX LEGENDS\n",
       "3  2020-12-15                  와 시즌7까지는 어디서 볼 수 있을까요  APEX LEGENDS\n",
       "4  2021-11-05                                 업뎃내용갱신  APEX LEGENDS"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('C:\\\\Users\\\\sh921\\\\Desktop\\\\InvenComment_preprocessed.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a7ffeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame  as df\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re \n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.wrappers.ldamallet import LdaMallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5dca4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#데이터 프레임의 'text' 열의 값들을 str 형식으로 바꾸기\n",
    "data.text = data.text.astype(str)\n",
    "\n",
    "\n",
    "#text와 timestamp 열을 기준으로 중복된 데이터를 삭제, inplace : 데이터 프레임을 변경할지 선택(원본을 대체)\n",
    "data.drop_duplicates(subset=['date','text','GameName'], inplace=True)\n",
    "\n",
    "#한글이 아니면 빈 문자열로 바꾸기\n",
    "data['text'] = data['text'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',regex=True)\n",
    "\n",
    "#빈 문자열 NAN 값으로 바꾸기\n",
    "data = data.replace({'': np.nan})\n",
    "data = data.replace(r'^\\s*$', None, regex=True)\n",
    "\n",
    "#NAN 이 있는 행은 삭제\n",
    "data.dropna(how='any', inplace=True)\n",
    "\n",
    "#인덱스 차곡차곡\n",
    "data = data.reset_index (drop = True)\n",
    "\n",
    "#데이터 프레임에 null 값이 있는지 확인\n",
    "print(data.isnull().values.any()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e589a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>GameName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>정성추 나름 체계적으로 게임이 진행되고있었네요  이런 스토리가</td>\n",
       "      <td>APEX LEGENDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-17</td>\n",
       "      <td>레이스 본명인  는 르네 일거에요두번 째  위에 점 빠진듯</td>\n",
       "      <td>APEX LEGENDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>스토리 보는거 정말 좋아하는 이런 정성 넘치는 정리 너무 감사합니다</td>\n",
       "      <td>APEX LEGENDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>와 시즌 까지는 어디서 볼 수 있을까요</td>\n",
       "      <td>APEX LEGENDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>업뎃내용갱신</td>\n",
       "      <td>APEX LEGENDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449172</th>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>되돌리기가 있으니까 필요없음</td>\n",
       "      <td>히어로즈 오브 더 스톰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449173</th>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>이제 이중폭탄웜홀 하나만 까지면 제라툴도 씹사기캐릭에서 그냥 평타캐로 벨런스 맞아질듯</td>\n",
       "      <td>히어로즈 오브 더 스톰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449174</th>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>는 용병캠프스틸금지를 제물로 바쳐서  중폭탄을 소환한다</td>\n",
       "      <td>히어로즈 오브 더 스톰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449175</th>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>유다이</td>\n",
       "      <td>히어로즈 오브 더 스톰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449176</th>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>그냥 원거리 암사자들은 숨도 못쉬겠네</td>\n",
       "      <td>히어로즈 오브 더 스톰</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449177 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                                             text  \\\n",
       "0       2020-11-12               정성추 나름 체계적으로 게임이 진행되고있었네요  이런 스토리가   \n",
       "1       2020-11-17                 레이스 본명인  는 르네 일거에요두번 째  위에 점 빠진듯   \n",
       "2       2020-11-19            스토리 보는거 정말 좋아하는 이런 정성 넘치는 정리 너무 감사합니다   \n",
       "3       2020-12-15                            와 시즌 까지는 어디서 볼 수 있을까요   \n",
       "4       2021-11-05                                           업뎃내용갱신   \n",
       "...            ...                                              ...   \n",
       "449172  2015-02-11                                  되돌리기가 있으니까 필요없음   \n",
       "449173  2015-02-11  이제 이중폭탄웜홀 하나만 까지면 제라툴도 씹사기캐릭에서 그냥 평타캐로 벨런스 맞아질듯   \n",
       "449174  2015-02-11                   는 용병캠프스틸금지를 제물로 바쳐서  중폭탄을 소환한다   \n",
       "449175  2015-02-11                                              유다이   \n",
       "449176  2015-02-11                             그냥 원거리 암사자들은 숨도 못쉬겠네   \n",
       "\n",
       "            GameName  \n",
       "0       APEX LEGENDS  \n",
       "1       APEX LEGENDS  \n",
       "2       APEX LEGENDS  \n",
       "3       APEX LEGENDS  \n",
       "4       APEX LEGENDS  \n",
       "...              ...  \n",
       "449172  히어로즈 오브 더 스톰  \n",
       "449173  히어로즈 오브 더 스톰  \n",
       "449174  히어로즈 오브 더 스톰  \n",
       "449175  히어로즈 오브 더 스톰  \n",
       "449176  히어로즈 오브 더 스톰  \n",
       "\n",
       "[449177 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602d26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_list=data.text.values.tolist()\n",
    "#(트윗 하나)씩 가져와서 명사만 추출한 후 리스트로 만들기\n",
    "data_word=[]\n",
    "for i in range(len(Data_list)):\n",
    "    try:\n",
    "        data_word.append(okt.nouns(Data_list[i]))\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "\n",
    "#명사추출이 부자연스러운 경우 사전에 명사 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77becac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#토픽모델링에 필요한 Dictionary 와 Corpus 만들기 (no_below = 100 빈도수 100이하 단어 제거)\n",
    "id2word=corpora.Dictionary(data_word)\n",
    "id2word.filter_extremes(no_below = 100)\n",
    "texts = data_word\n",
    "corpus=[id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b71c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mallet_path = 'C:\\\\Users\\\\sh921\\\\Desktop\\\\mallet-2.0.8\\\\mallet-2.0.8\\\\bin\\\\mallet' \n",
    "import os\n",
    "os.environ['MALLET_HOME'] = 'C:\\\\Users\\\\sh921\\\\Desktop\\\\mallet-2.0.8\\\\mallet-2.0.8\\\\'\n",
    "ldamallet = LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)\n",
    "print(ldamallet.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d700473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda모델의 일관성 점수 계산\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b597958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#최적의 토픽 수를 찾기 위해 여러 토픽 수로 일관성을 계산하고 비교\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=14, step=2):\n",
    "\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=data_word, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9d7cfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texts, start=6, limit=41, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eafce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일관성 점수 그래프 보기\n",
    "limit=41; start=6; step=2;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78690149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽수 별 일관성 점수 확인\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ffaf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽 수 선택하고 토픽들(단어) 확인\n",
    "optimal_model = model_list[6]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "print(optimal_model.print_topics(num_words=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#트윗들의 토픽을 확인 (토픽별로)\n",
    "def format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=texts):\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    #ldamodel[corpus]: lda_model에 corpus를 넣어 각 토픽 당 확률을 알 수 있음\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0: \n",
    "                wp = ldamodel.show_topic(topic_num,topn=40)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=Data_list)\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "\n",
    "df_dominant_topic=df_dominant_topic.sort_values(by=['Dominant_Topic'])\n",
    "df_dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce9101",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 각 토픽에서 가장 대표적인 문장 찾기\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "\n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "topic_counts.sort_index(inplace=True)\n",
    "\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "topic_contribution\n",
    "\n",
    "lda_inform = pd.concat([sent_topics_sorteddf_mallet, topic_counts, topic_contribution], axis=1)\n",
    "lda_inform.columns=[\"Topic_Num\", \"Topic_Perc_Contrib\", \"Keywords\", \"Text\", \"Num_Documents\", \"Perc_Documents\"]\n",
    "\n",
    "\n",
    "lda_inform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc50899b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lda_inform.to_csv (\"C:\\\\Users\\\\sh921\\\\Desktop\\\\LDA_inven.csv\", index = None)\n",
    "lda_inform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8e0cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
